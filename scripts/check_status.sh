#!/bin/bash

# H200 Status Check Script
# Quick status check for the Xinfluencer AI system

echo "üîç Xinfluencer AI H200 Status Check"
echo "=================================="

# Check if we're on H200 server
if [ -f "/home/ubuntu/xinfluencer/start_xinfluencer.sh" ]; then
    echo "‚úÖ Running on H200 server"
    cd /home/ubuntu/xinfluencer
    
    echo ""
    echo "üìä GPU Status:"
    nvidia-smi --query-gpu=name,memory.total,memory.used,memory.free,temperature.gpu,utilization.gpu --format=csv
    
    echo ""
    echo "üêç Python Environment:"
    python3 --version
    
    echo ""
    echo "üì¶ Key Packages:"
    python3 -c "import torch; print(f'PyTorch: {torch.__version__}')" 2>/dev/null || echo "PyTorch: Not installed"
    python3 -c "import transformers; print(f'Transformers: {transformers.__version__}')" 2>/dev/null || echo "Transformers: Not installed"
    
    echo ""
    echo "üìÅ Project Status:"
    if [ -f "src/main.py" ]; then
        echo "‚úÖ Main script exists"
    else
        echo "‚ùå Main script missing"
    fi
    
    if [ -f "requirements.txt" ]; then
        echo "‚úÖ Requirements file exists"
    else
        echo "‚ùå Requirements file missing"
    fi
    
    echo ""
    echo "üöÄ Quick Test:"
    python3 -c "
import sys
sys.path.insert(0, 'src')
try:
    from model.generate import TextGenerator
    print('‚úÖ Model module imports successfully')
except Exception as e:
    print(f'‚ùå Model module import failed: {e}')
" 2>/dev/null
    
else
    echo "‚ùå Not running on H200 server"
    echo "Run this script on the H200 server or use: ./ssh_h200.sh"
fi

echo ""
echo "=================================="
echo "For detailed testing, run: python3 scripts/test_h200_setup.py"